{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Stock Prices from Expected Earnings\n",
    "## 1. Overview\n",
    "This project uses a Recurrent Neural Network (RNN) through TensorFlow to predict stock prices the day after an earnings report. It takes as input the daily stock prices for the (approximately) 3-month period leading up to the earnings report, as well as the expected Earnings Per Share (EPS) prior to the report. Its output is the expected % difference between the next day's closing price and the previous day's high price.\n",
    "## 2. Collecting and Cleaning Data\n",
    "Data will be taken from the last 8 years' historical stock prices and earnings reports. It is housed in stocks_latest, which you should download on your own at <a href=\"https://www.kaggle.com/tsaustin/us-historical-stock-prices-with-earnings-data\">this link</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the packages we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.tseries.offsets import BDay\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll extract our data as pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_data_path = \"./datasets/stock_prices_latest.csv\"\n",
    "earnings_data_path = \"./datasets/earnings_latest.csv\"\n",
    "\n",
    "stocks_df = pd.read_csv(stocks_data_path)\n",
    "earnings_df = pd.read_csv(earnings_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what data our stocks file contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23528435 entries, 0 to 23528434\n",
      "Data columns (total 9 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   symbol             object \n",
      " 1   date               object \n",
      " 2   open               float64\n",
      " 3   high               float64\n",
      " 4   low                float64\n",
      " 5   close              float64\n",
      " 6   close_adjusted     float64\n",
      " 7   volume             int64  \n",
      " 8   split_coefficient  float64\n",
      "dtypes: float64(6), int64(1), object(2)\n",
      "memory usage: 1.6+ GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>close_adjusted</th>\n",
       "      <th>volume</th>\n",
       "      <th>split_coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2016-05-16</td>\n",
       "      <td>50.80</td>\n",
       "      <td>51.96</td>\n",
       "      <td>50.75</td>\n",
       "      <td>51.83</td>\n",
       "      <td>49.7013</td>\n",
       "      <td>20032017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2002-01-16</td>\n",
       "      <td>68.85</td>\n",
       "      <td>69.84</td>\n",
       "      <td>67.85</td>\n",
       "      <td>67.87</td>\n",
       "      <td>22.5902</td>\n",
       "      <td>30977700</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2001-09-18</td>\n",
       "      <td>53.41</td>\n",
       "      <td>55.00</td>\n",
       "      <td>53.17</td>\n",
       "      <td>54.32</td>\n",
       "      <td>18.0802</td>\n",
       "      <td>41591300</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2007-10-26</td>\n",
       "      <td>36.01</td>\n",
       "      <td>36.03</td>\n",
       "      <td>34.56</td>\n",
       "      <td>35.03</td>\n",
       "      <td>27.2232</td>\n",
       "      <td>288121200</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2014-06-27</td>\n",
       "      <td>41.61</td>\n",
       "      <td>42.29</td>\n",
       "      <td>41.51</td>\n",
       "      <td>42.25</td>\n",
       "      <td>38.6773</td>\n",
       "      <td>74640000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date   open   high    low  close  close_adjusted     volume  \\\n",
       "0   MSFT  2016-05-16  50.80  51.96  50.75  51.83         49.7013   20032017   \n",
       "1   MSFT  2002-01-16  68.85  69.84  67.85  67.87         22.5902   30977700   \n",
       "2   MSFT  2001-09-18  53.41  55.00  53.17  54.32         18.0802   41591300   \n",
       "3   MSFT  2007-10-26  36.01  36.03  34.56  35.03         27.2232  288121200   \n",
       "4   MSFT  2014-06-27  41.61  42.29  41.51  42.25         38.6773   74640000   \n",
       "\n",
       "   split_coefficient  \n",
       "0                1.0  \n",
       "1                1.0  \n",
       "2                1.0  \n",
       "3                1.0  \n",
       "4                1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df.info()\n",
    "stocks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the following to clean up this dataset:\n",
    "1. Remove split_coefficient and close, opting for close_adjusted instead\n",
    "2. Rename close_adjusted to close\n",
    "3. Convert our dates to datetime objects in pandas\n",
    "4. Sort first by symbol, then by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19762470</th>\n",
       "      <td>A</td>\n",
       "      <td>1999-11-18</td>\n",
       "      <td>45.50</td>\n",
       "      <td>50.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>44739900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762410</th>\n",
       "      <td>A</td>\n",
       "      <td>1999-11-19</td>\n",
       "      <td>42.94</td>\n",
       "      <td>43.00</td>\n",
       "      <td>39.81</td>\n",
       "      <td>10897100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762440</th>\n",
       "      <td>A</td>\n",
       "      <td>1999-11-22</td>\n",
       "      <td>41.31</td>\n",
       "      <td>44.00</td>\n",
       "      <td>40.06</td>\n",
       "      <td>4705200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762399</th>\n",
       "      <td>A</td>\n",
       "      <td>1999-11-23</td>\n",
       "      <td>42.50</td>\n",
       "      <td>43.63</td>\n",
       "      <td>40.25</td>\n",
       "      <td>4274400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19762394</th>\n",
       "      <td>A</td>\n",
       "      <td>1999-11-24</td>\n",
       "      <td>40.13</td>\n",
       "      <td>41.94</td>\n",
       "      <td>40.00</td>\n",
       "      <td>3464400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         symbol       date   open   high    low    volume\n",
       "19762470      A 1999-11-18  45.50  50.00  40.00  44739900\n",
       "19762410      A 1999-11-19  42.94  43.00  39.81  10897100\n",
       "19762440      A 1999-11-22  41.31  44.00  40.06   4705200\n",
       "19762399      A 1999-11-23  42.50  43.63  40.25   4274400\n",
       "19762394      A 1999-11-24  40.13  41.94  40.00   3464400"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_df.drop(['split_coefficient','close'], axis=1, errors='ignore', inplace=True)\n",
    "stocks_df.rename(columns={'close_adjusted':'close'}, inplace=True)\n",
    "stocks_df['date'] = pd.to_datetime(stocks_df.date)\n",
    "stocks_df.sort_values(by=['symbol','date'], inplace=True)\n",
    "stocks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be feeding our NN the stock prices for each 90-day period leading up to an earnings report. First, we'll group the stock data by symbol and save as numpy arrays for faster processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20646711</th>\n",
       "      <td>ZM</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>65.00</td>\n",
       "      <td>66.000</td>\n",
       "      <td>60.321</td>\n",
       "      <td>25764659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646712</th>\n",
       "      <td>ZM</td>\n",
       "      <td>2019-04-22</td>\n",
       "      <td>61.00</td>\n",
       "      <td>68.900</td>\n",
       "      <td>59.940</td>\n",
       "      <td>9949738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646710</th>\n",
       "      <td>ZM</td>\n",
       "      <td>2019-04-23</td>\n",
       "      <td>66.87</td>\n",
       "      <td>74.169</td>\n",
       "      <td>65.550</td>\n",
       "      <td>6786513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646715</th>\n",
       "      <td>ZM</td>\n",
       "      <td>2019-04-24</td>\n",
       "      <td>71.40</td>\n",
       "      <td>71.500</td>\n",
       "      <td>63.160</td>\n",
       "      <td>4973529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20646709</th>\n",
       "      <td>ZM</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>64.74</td>\n",
       "      <td>66.850</td>\n",
       "      <td>62.600</td>\n",
       "      <td>3863275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         symbol       date   open    high     low    volume\n",
       "20646711     ZM 2019-04-18  65.00  66.000  60.321  25764659\n",
       "20646712     ZM 2019-04-22  61.00  68.900  59.940   9949738\n",
       "20646710     ZM 2019-04-23  66.87  74.169  65.550   6786513\n",
       "20646715     ZM 2019-04-24  71.40  71.500  63.160   4973529\n",
       "20646709     ZM 2019-04-25  64.74  66.850  62.600   3863275"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks_sep = dict(tuple(stocks_df.groupby('symbol')))\n",
    "symbol1 = stocks_sep['ZM']\n",
    "symbol1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to use our earnings data, and particularly the dates of earnings periods for each company, to further separate our data into 90-day chunks. Let's clean and explore our earnings data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 77282 entries, 14 to 160659\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   symbol          77282 non-null  object        \n",
      " 1   date            77282 non-null  datetime64[ns]\n",
      " 2   eps_est         77282 non-null  float64       \n",
      " 3   eps             77282 non-null  float64       \n",
      " 4   earnings_start  77282 non-null  datetime64[ns]\n",
      " 5   earnings_end    77282 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](3), float64(2), object(1)\n",
      "memory usage: 4.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>eps_est</th>\n",
       "      <th>eps</th>\n",
       "      <th>earnings_start</th>\n",
       "      <th>earnings_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2012-11-19</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2012-11-20</td>\n",
       "      <td>2013-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>2013-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-11-14</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>2013-11-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol       date  eps_est   eps earnings_start earnings_end\n",
       "14      A 2012-11-19     0.80  0.84     2012-09-04   2012-11-16\n",
       "15      A 2013-02-14     0.66  0.63     2012-11-20   2013-02-13\n",
       "16      A 2013-05-14     0.67  0.77     2013-02-15   2013-05-13\n",
       "17      A 2013-08-14     0.62  0.68     2013-05-15   2013-08-13\n",
       "18      A 2013-11-14     0.76  0.81     2013-08-15   2013-11-13"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_df.dropna(inplace=True)\n",
    "earnings_df.drop(['release_time', 'qtr'], axis=1, errors='ignore', inplace=True)\n",
    "earnings_df['date'] = pd.to_datetime(earnings_df.date)\n",
    "earnings_df.sort_values(by=['symbol', 'date'], inplace=True)\n",
    "earnings_df.info()\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the start and end dates for each earnings period to split our input data. Let's calculate them and assign them to two new columns in earnings_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>eps_est</th>\n",
       "      <th>eps</th>\n",
       "      <th>earnings_start</th>\n",
       "      <th>earnings_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>2012-11-19</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2012-09-04</td>\n",
       "      <td>2012-11-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-02-14</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "      <td>2012-11-20</td>\n",
       "      <td>2013-02-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.77</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>2013-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-08-14</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>2013-08-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A</td>\n",
       "      <td>2013-11-14</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2013-08-15</td>\n",
       "      <td>2013-11-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   symbol       date  eps_est   eps earnings_start earnings_end\n",
       "14      A 2012-11-19     0.80  0.84     2012-09-04   2012-11-16\n",
       "15      A 2013-02-14     0.66  0.63     2012-11-20   2013-02-13\n",
       "16      A 2013-05-14     0.67  0.77     2013-02-15   2013-05-13\n",
       "17      A 2013-08-14     0.62  0.68     2013-05-15   2013-08-13\n",
       "18      A 2013-11-14     0.76  0.81     2013-08-15   2013-11-13"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_earnings_start(df):\n",
    "    date_df = pd.DataFrame(df['date'])\n",
    "    date_df = df['date'].shift(periods=1) + BDay(1)\n",
    "    date_df.iat[0] = df['date'].iloc[0] - BDay(54)\n",
    "    return date_df\n",
    "\n",
    "def calculate_earnings_end(df):\n",
    "    return df['date'] - BDay(1)\n",
    "\n",
    "earnings_df['earnings_start'] = calculate_earnings_start(earnings_df)\n",
    "earnings_df['earnings_end'] = calculate_earnings_end(earnings_df)\n",
    "earnings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       symbol       date  eps_est   eps earnings_start earnings_end\n",
      "160389     ZM 2019-09-05    0.013  0.08     2020-03-20   2019-09-04\n",
      "160390     ZM 2019-12-05    0.028  0.09     2019-09-06   2019-12-04\n",
      "160391     ZM 2020-03-04    0.071  0.15     2019-12-06   2020-03-03\n",
      "4328\n"
     ]
    }
   ],
   "source": [
    "earnings_sep = dict(tuple(earnings_df.groupby('symbol')))\n",
    "delete_dict = []\n",
    "for symbol in earnings_sep:\n",
    "    try:\n",
    "        stocks_sep[symbol]\n",
    "    except:\n",
    "        delete_dict.append(symbol)\n",
    "for symbol in delete_dict:\n",
    "    del earnings_sep[symbol]\n",
    "symbol2 = earnings_sep['ZM']\n",
    "print(symbol2)\n",
    "print(len(earnings_sep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now iterate through our earnings and generate input period and output percent increases for our RNN.\n",
    "\n",
    "_Note: this is pretty slow and could be improved with .apply() or with vectorization._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stocks processed: 100/4328'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stocks_cnt = 0\n",
    "stocks_total_cnt = len(earnings_sep)\n",
    "input_data = []\n",
    "output_data = []\n",
    "earnings_sep_test = {k: earnings_sep[k] for k in list(earnings_sep)[:100]}\n",
    "for symbol in earnings_sep_test:\n",
    "    curr_stock = stocks_sep[symbol]\n",
    "    stocks_cnt += 1\n",
    "    if stocks_cnt % 100 == 0 or stocks_cnt == stocks_total_cnt:\n",
    "        clear_output(wait=True)\n",
    "        display('stocks processed: '+str(stocks_cnt)+'/'+str(stocks_total_cnt))\n",
    "    for earnings_row in earnings_sep_test[symbol].itertuples():\n",
    "        # compute input data\n",
    "        stock_period_data = curr_stock[(curr_stock.date >= earnings_row.earnings_start) & (curr_stock.date <= earnings_row.earnings_end)]\n",
    "        \n",
    "        # compute output data\n",
    "        earnings_prev_high = curr_stock[curr_stock.date == earnings_row.date].high.to_numpy()\n",
    "        earnings_next_open = curr_stock[curr_stock.date == earnings_row.date + BDay(1)].open.to_numpy()\n",
    "        percent_change = (earnings_next_open - earnings_prev_high) / earnings_prev_high\n",
    "        \n",
    "        # clean and store data\n",
    "        stock_period_data.drop(['symbol', 'date'], axis=1, errors='ignore', inplace=True)\n",
    "        input_data.append(stock_period_data)\n",
    "        output_data.append(percent_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll shuffle our data and separate it into training (64%), dev (16%) and test (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\ipykernel_launcher.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  import sys\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-73030265fba7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "x, y = shuffle(input_data, output_data)\n",
    "for i in range(0, len(x)):\n",
    "    x[i] = np.array(x[i].to_numpy())\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "x_train, x_dev, y_train, y_dev = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize stock data earlier on\n",
    "# construct RNN\n",
    "# feed input/output to neural net\n",
    "# try to predict on recent earnings like ZM and CRM\n",
    "# predict earnings week of 12/7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now construct our neural network model with convolutional and LSTM layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (2,2), padding='same', activation=tf.nn.relu,\n",
    "                          input_shape=[None, None, 1]),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (2,2), padding='same', activation=tf.nn.relu),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    #tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model with our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv2d_34_input to have 4 dimensions, but got array with shape (74, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-c03765e60979>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[1;32m--> 646\u001b[1;33m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[0;32m    647\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2383\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2410\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2412\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\code\\ml\\stocks_earnings\\envs\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    571\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    574\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv2d_34_input to have 4 dimensions, but got array with shape (74, 4)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stocks",
   "language": "python",
   "name": "stocks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
